{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5bN/NTzJhn/DUkL7Gy4JF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nettorobson/pyspark_delta_tests/blob/main/spark_colab_imdb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDUxC1lyplYj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PySpark\n",
        "\n",
        "###"
      ],
      "metadata": {
        "id": "ZtDuYC8ar3VR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalação do java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "metadata": {
        "id": "XOTf2blWpn27"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Python script you provided is a shell command that installs the OpenJDK 8 (Java Development Kit) without a graphical user interface in a Google Colab environment. Let's break down each part of the command:\n",
        "\n",
        "Explanation of the components:\n",
        "- !: This symbol tells the Jupyter or Colab notebook that the following line is a shell command rather than Python code. In Google Colab, using ! allows you to run terminal commands directly.\n",
        "apt-get install:\n",
        "\n",
        "- apt-get is a package management tool used in Debian-based Linux distributions (like Ubuntu, which Google Colab uses) to install, update, or remove software packages.\n",
        "install is the argument that tells apt-get to install the specified package—in this case, OpenJDK 8.\n",
        "- openjdk-8-jdk-headless: openjdk-8-jdk refers to the OpenJDK (Java Development Kit) version 8, which is an open-source implementation of the Java Platform, Standard Edition.\n",
        "- headless specifies that this version does not include any GUI (Graphical User Interface) components, which is useful in environments like Google Colab, where graphical applications are not needed. It's more lightweight and suitable for server or cloud environments.\n",
        "- qq: This stands for \"quiet mode.\" It tells apt-get to suppress unnecessary output during the installation process. Only essential messages will be displayed. Adding this flag reduces the amount of text printed in the Colab notebook, making the output cleaner.\n",
        "- /dev/null: This redirects all output from the command to /dev/null, which is a special file in Linux that discards everything written to it.\n",
        "Essentially, this part of the command suppresses any output (errors or logs) from appearing in the Colab notebook. Combined with -qq, it ensures that the installation process runs quietly without printing any messages.\n",
        "\n",
        "<br>Summary:\n",
        "This command installs OpenJDK 8 (Java Development Kit) in a \"headless\" mode (without a graphical user interface) on a Debian-based system like the one in Google Colab. It runs quietly, suppressing both output and error messages, keeping the notebook output clean.\n"
      ],
      "metadata": {
        "id": "tAgPFb_rrYrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixando a versão mais recente+estável do Spark\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.4.3/spark-3.4.3-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "Ajtlr0A_r1Ox"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Python script you provided is a shell command to download a file from the web using the wget tool in the Google Colab environment.\n",
        "\n",
        "This command downloads the compressed Apache Spark 3.5.3 binary (compiled to work with Hadoop 3) from the Apache website. The -q flag suppresses output, so the download process runs quietly, only showing errors if they occur. This is typically done when setting up Spark for distributed data processing in the Google Colab environment.\n",
        "\n",
        "- wget is a command-line utility for downloading files from the web. It supports protocols such as HTTP, HTTPS, and FTP, making it useful for retrieving files over the internet.\n",
        "\n",
        "- https://www.apache.org/dyn/closer.lua/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz: This is the URL of the file that wget will download.\n",
        "The file being downloaded is spark-3.5.3-bin-hadoop3.tgz, which is an archive containing Apache Spark version 3.5.3, bundled with Hadoop 3.\n",
        " - Spark is a distributed computing framework used for big data processing.\n",
        " - Hadoop 3 is a framework for distributed storage and processing of large datasets across clusters of computers.\n",
        "The .tgz extension indicates that the file is a compressed **tarball** archive (similar to a .zip file but commonly used in Unix/Linux systems). It combines .tar for archiving and .gz for compression.\n",
        "The specific URL (ending in .lua) redirects to a mirror site closer to the user's location to download the requested file efficiently"
      ],
      "metadata": {
        "id": "NCB3yrpcsukr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descompactar o spark .tgz\n",
        "!tar xf /content/spark-3.4.3-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "Wm47ziUQss9z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation of the components:\n",
        "\n",
        "- !: This symbol indicates that the line is a shell command, **not Python code**. It allows you to run _terminal commands_ directly in Google Colab.\n",
        "tar:\n",
        "\n",
        "- tar is a Unix command used to work with tarball files (which are compressed or uncompressed archive files). The .tar format is commonly used for bundling multiple files and directories into one file.\n",
        "\n",
        "- xf: These are options passed to the tar command:\n",
        " - x: Extract mode. This option tells tar to extract the contents of the archive file.\n",
        " - f: File. This option specifies that you're working with a file, followed by the path to the file (/content/spark-3.4.3-bin-hadoop3.tgz.1).\n",
        "/content/spark-3.4.3-bin-hadoop3.tgz.1:\n",
        "\n",
        "  This is the path to the archive file that you're extracting. In this case:\n",
        "The file is located in the /content/ directory of the Google Colab environment.\n",
        "The file name is spark-3.4.3-bin-hadoop3.tgz.1.\n",
        "The .tgz extension indicates that this is a tarball file compressed with Gzip.\n",
        "The .1 suffix might indicate that this file is a duplicate download (Google Colab appends .1, .2, etc., if the same file is downloaded multiple times).\n",
        "This file contains Apache Spark version 3.4.3, bundled with Hadoop 3.\n",
        "\n",
        "\n",
        "**Summary:**\n",
        "This command extracts the contents of the file spark-3.4.3-bin-hadoop3.tgz.1, which is a Gzipped tar archive containing Apache Spark 3.4.3 for Hadoop 3, in the Google Colab environment. After running the command, the extracted files will be available in the current working directory (/content/ in this case)."
      ],
      "metadata": {
        "id": "RoDS7pZg3jOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando as variáveis de ambiente\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.3-bin-hadoop3\""
      ],
      "metadata": {
        "id": "UfZLGvRrvp0H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Python script you provided sets up environment variables in the Google Colab environment, which are necessary for configuring Java and Apache Spark. Let's break down each part:\n",
        "\n",
        "#### Explanation:\n",
        "\n",
        "- import os: This imports the os module, which provides functions to interact with the operating system. One of its functionalities is setting environment variables using the os.environ method.\n",
        "\n",
        "- os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\": This line sets the JAVA_HOME environment variable.\n",
        "JAVA_HOME is used by Java-based applications to locate the Java installation directory. In this case, it is set to the path /usr/lib/jvm/java-8-openjdk-amd64, which is where Java 8 (OpenJDK) is installed in the Colab environment.\n",
        "**Setting this variable ensures that when Java is required (for example, by Apache Spark), it can correctly locate the Java installation.**\n",
        "\n",
        "- os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.3-bin-hadoop3\": This line sets the SPARK_HOME environment variable.\n",
        "SPARK_HOME is used to tell the system where Apache Spark is installed. In this case, it is set to the path /content/spark-3.4.3-bin-hadoop3, which is the directory where Apache Spark version 3.4.3 (with Hadoop 3) is extracted.\n",
        "**By setting this variable, tools and scripts that need to interact with Spark can easily locate its installation.**\n",
        "\n",
        "#### Summary:\n",
        "This script sets two environment variables, JAVA_HOME and SPARK_HOME, which are essential for ensuring that Apache Spark can correctly find Java and its own installation path. This setup is typically done when configuring Spark to run in Google Colab.\n",
        "\n",
        "JAVA_HOME points to the Java 8 OpenJDK installation, which is required for running Spark.\n",
        "SPARK_HOME points to the directory where Spark 3.4.3 with Hadoop 3 is located.\n",
        "These settings are necessary before running Spark-based applications or interacting with Spark in the Colab environment.\n",
        "\n"
      ],
      "metadata": {
        "id": "Vcj9GPCd5F2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar a lib 'findspark' que a juda a localizar o Spark no sistema e importá-lo como uma biblioteca regular\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "ref2a3qbwQG9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar a lib findspark baixada e inicializar a lib\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "tRvEmc4-zTZ5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**According the documentation:**\n",
        "\n",
        "PySpark isn't on sys.path by default, but that doesn't mean it can't be used as a regular library. You can address this by either symlinking pyspark into your site-packages, or adding pyspark to sys.path at runtime. findspark does the latter.\n",
        "\n",
        "To initialize PySpark, just call\n",
        "\n",
        "```\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "import pyspark\n",
        "sc = pyspark.SparkContext(appName=\"myAppName\")\n",
        "```\n",
        "Without any arguments, the SPARK_HOME environment variable will be used, and if that isn't set, other possible install locations will be checked.\n",
        "\n",
        "Alternatively, you can specify a location with the spark_home argument.\n",
        "\n",
        "```\n",
        "findspark.init('/path/to/spark_home')\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NXIr-eK57MAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 2: Spark Session\n"
      ],
      "metadata": {
        "id": "P6SDTvpJ9caU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar a Spark Session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "        .master('local')\\\n",
        "        .appName('sparkcolab')\\\n",
        "        .getOrCreate()"
      ],
      "metadata": {
        "id": "kUFcEGpHzfyc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Python script sets up a PySpark session in the Google Colab environment, allowing you to use Apache Spark's distributed computing capabilities for data processing. Let's break it down step by step:\n",
        "\n",
        "#### Explanation of the components:\n",
        "\n",
        "- from pyspark.sql import SparkSession: This imports the SparkSession class from PySpark's SQL module.\n",
        "***SparkSession is the entry point for using Apache Spark in Python**. It provides an interface for programming with Spark, including reading data, creating dataframes, and running queries.\n",
        "\n",
        "- spark = SparkSession.builder: **The SparkSession.builder is a constructor that initializes the configuration needed to create a new Spark session.**\n",
        "The session (spark) is an instance that will allow you to run Spark operations, such as loading datasets, performing transformations, and executing distributed computations.\n",
        "\n",
        "- .master('local'): **The .master() method sets the cluster manager or the mode in which Spark will run.**\n",
        "The argument 'local' means that Spark will run locally on the current machine (_in this case, on Google Colab_) rather than on a cluster of distributed machines. It will use the available CPU cores for processing. **This is suitable for testing or small-scale data processing on Google Colab.**\n",
        "\n",
        "- .appName('sparkcolab'): The .appName() method assigns a name to your Spark application.\n",
        "In this case, the application is named 'sparkcolab'. **This name is primarily for identification in logs or Spark's web UI (which can be useful when running multiple applications).**\n",
        "It helps distinguish different Spark jobs and makes tracking easier.\n",
        "\n",
        "- .getOrCreate(): **This method either retrieves an existing Spark session if one is already running or creates a new one if no session exists.**\n",
        "<br>*This ensures that only one Spark session runs in your environment at a time.*<br>\n",
        "What the script does:\n",
        "\n",
        "\n",
        "This script sets up a Spark session in Google Colab, configuring it to run locally on the machine with the name 'sparkcolab'. The session created by this script will allow you to work with Spark's distributed computing capabilities, enabling tasks such as data loading, transformation, and analysis using Spark DataFrames or SQL-like operations.\n",
        "\n",
        "**Summary of the Arguments:**\n",
        "master('local'): Runs Spark in \"local\" mode, which processes data on the current machine.\n",
        "appName('sparkcolab'): Assigns the name 'sparkcolab' to the Spark application.\n",
        "getOrCreate(): Retrieves or creates a Spark session to interact with Spark's APIs.\n",
        "This script is essential for initializing Spark in a Colab environment to use PySpark for data processing tasks.\n"
      ],
      "metadata": {
        "id": "jS9KBKCDERRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 3: Dataset"
      ],
      "metadata": {
        "id": "WkBKqdB6MKdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar o Dataset\n",
        "# Abrir um input para carregar os arquivos do ambiente local\n",
        "from google.colab import files\n",
        "arquivo = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "kGkzab92Lifx",
        "outputId": "b4475802-549a-4e27-d0ba-e1dc68c89525"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9f364142-5d41-4083-aecf-e619de2a1ac6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9f364142-5d41-4083-aecf-e619de2a1ac6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving title.ratings.tsv to title.ratings (1).tsv\n",
            "Saving title.basics.tsv to title.basics.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DSV (Delimiter separated Values) como .csv ou .tsv (este caso), são suportados por vários módulos python, como o PySpark e o Pandas.\n",
        "\n",
        "Neste caso, bastou passar como argumento o separador (tab) para ele fazer a leitura corretamento do Spark Dataframe mais abaixo:\n",
        "\n",
        "```\n",
        " sep=r'\\t'\n",
        "```\n"
      ],
      "metadata": {
        "id": "MJRi-cjNiluY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(arquivo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNyK4Dm5ML1G",
        "outputId": "64260409-d68f-463f-a120-1bb2ce708232"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('title.basics.tsv', header=True, sep=r'\\t', inferSchema=True)"
      ],
      "metadata": {
        "id": "CRHJzPtveBi_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checar o schema se está tudo certo e tipos de dados\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdNCEobFePmY",
        "outputId": "ddd5bd75-95ca-4c0f-974a-ab125c7773bc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- tconst: string (nullable = true)\n",
            " |-- titleType: string (nullable = true)\n",
            " |-- primaryTitle: string (nullable = true)\n",
            " |-- originalTitle: string (nullable = true)\n",
            " |-- isAdult: string (nullable = true)\n",
            " |-- startYear: string (nullable = true)\n",
            " |-- endYear: string (nullable = true)\n",
            " |-- runtimeMinutes: string (nullable = true)\n",
            " |-- genres: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checar o df como foi montada\n",
        "df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukLvVtYZfWo2",
        "outputId": "02e67560-bb95-4639-a2fe-a987e3ce9a10"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+\n",
            "|   tconst|titleType|        primaryTitle|       originalTitle|isAdult|startYear|endYear|runtimeMinutes|              genres|\n",
            "+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+\n",
            "|tt0000001|    short|          Carmencita|          Carmencita|      0|     1894|     \\N|             1|   Documentary,Short|\n",
            "|tt0000002|    short|Le clown et ses c...|Le clown et ses c...|      0|     1892|     \\N|             5|     Animation,Short|\n",
            "|tt0000003|    short|      Pauvre Pierrot|      Pauvre Pierrot|      0|     1892|     \\N|             5|Animation,Comedy,...|\n",
            "|tt0000004|    short|         Un bon bock|         Un bon bock|      0|     1892|     \\N|            12|     Animation,Short|\n",
            "|tt0000005|    short|    Blacksmith Scene|    Blacksmith Scene|      0|     1893|     \\N|             1|        Comedy,Short|\n",
            "|tt0000006|    short|   Chinese Opium Den|   Chinese Opium Den|      0|     1894|     \\N|             1|               Short|\n",
            "|tt0000007|    short|Corbett and Court...|Corbett and Court...|      0|     1894|     \\N|             1|         Short,Sport|\n",
            "|tt0000008|    short|Edison Kinetoscop...|Edison Kinetoscop...|      0|     1894|     \\N|             1|   Documentary,Short|\n",
            "|tt0000009|    movie|          Miss Jerry|          Miss Jerry|      0|     1894|     \\N|            45|             Romance|\n",
            "|tt0000010|    short| Leaving the Factory|La sortie de l'us...|      0|     1895|     \\N|             1|   Documentary,Short|\n",
            "+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar df dos reviews\n",
        "df_reviews = spark.read.csv('title.ratings.tsv', header=True, sep=r'\\t', inferSchema=True)\n",
        "df_reviews.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3dKT20ZCXA6",
        "outputId": "5898233c-ae4a-432c-ff36-ea5e2a4b6217"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------+--------+\n",
            "|   tconst|averageRating|numVotes|\n",
            "+---------+-------------+--------+\n",
            "|tt0000001|          5.7|    2090|\n",
            "|tt0000002|          5.6|     283|\n",
            "|tt0000003|          6.5|    2094|\n",
            "|tt0000004|          5.4|     184|\n",
            "|tt0000005|          6.2|    2828|\n",
            "|tt0000006|          5.0|     196|\n",
            "|tt0000007|          5.4|     889|\n",
            "|tt0000008|          5.4|    2233|\n",
            "|tt0000009|          5.4|     214|\n",
            "|tt0000010|          6.8|    7699|\n",
            "+---------+-------------+--------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_reviews.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_J5dj9paNU8",
        "outputId": "ce87238e-0e02-4ecd-f1df-c00d945ddef6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- tconst: string (nullable = true)\n",
            " |-- averageRating: double (nullable = true)\n",
            " |-- numVotes: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 4: Explorando o dataset/engenharia de atributos"
      ],
      "metadata": {
        "id": "0pJcHGV0tTUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecionar colunas\n",
        "df_movie = df.select('primaryTitle', 'titleType', 'startYear','genres')"
      ],
      "metadata": {
        "id": "A-hul4uUfdFt"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar colunas\n",
        "df_movie.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUKljgzvtjvl",
        "outputId": "443df4ce-8462-4288-ca7b-b0000fe35753"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+---------+--------------------+\n",
            "|        primaryTitle|titleType|startYear|              genres|\n",
            "+--------------------+---------+---------+--------------------+\n",
            "|          Carmencita|    short|     1894|   Documentary,Short|\n",
            "|Le clown et ses c...|    short|     1892|     Animation,Short|\n",
            "|      Pauvre Pierrot|    short|     1892|Animation,Comedy,...|\n",
            "|         Un bon bock|    short|     1892|     Animation,Short|\n",
            "|    Blacksmith Scene|    short|     1893|        Comedy,Short|\n",
            "|   Chinese Opium Den|    short|     1894|               Short|\n",
            "|Corbett and Court...|    short|     1894|         Short,Sport|\n",
            "|Edison Kinetoscop...|    short|     1894|   Documentary,Short|\n",
            "|          Miss Jerry|    movie|     1894|             Romance|\n",
            "| Leaving the Factory|    short|     1895|   Documentary,Short|\n",
            "+--------------------+---------+---------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando um novo campo\n",
        "# O campo 'startYear' está como string\n",
        "df_year = df_movie.withColumn('year', df_movie['startYear'].cast('int')).drop('startYear')\n",
        "df_year.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwxShSMPv5Ze",
        "outputId": "e949044f-56da-4fe9-bda3-ad378c941be6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+--------------------+----+\n",
            "|        primaryTitle|titleType|              genres|year|\n",
            "+--------------------+---------+--------------------+----+\n",
            "|          Carmencita|    short|   Documentary,Short|1894|\n",
            "|Le clown et ses c...|    short|     Animation,Short|1892|\n",
            "|      Pauvre Pierrot|    short|Animation,Comedy,...|1892|\n",
            "|         Un bon bock|    short|     Animation,Short|1892|\n",
            "|    Blacksmith Scene|    short|        Comedy,Short|1893|\n",
            "|   Chinese Opium Den|    short|               Short|1894|\n",
            "|Corbett and Court...|    short|         Short,Sport|1894|\n",
            "|Edison Kinetoscop...|    short|   Documentary,Short|1894|\n",
            "|          Miss Jerry|    movie|             Romance|1894|\n",
            "| Leaving the Factory|    short|   Documentary,Short|1895|\n",
            "+--------------------+---------+--------------------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_year.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUhRJnEGavmo",
        "outputId": "d42dfcb8-bf43-4ddd-d041-b0d49d5e49b2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- primaryTitle: string (nullable = true)\n",
            " |-- titleType: string (nullable = true)\n",
            " |-- genres: string (nullable = true)\n",
            " |-- year: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrando pela nova coluna, mas sem armazenar em um novo objeto\n",
        "df_year.filter(df_year.year > 2020).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcRLlRNi8Moc",
        "outputId": "37601392-fc6e-41bd-e1be-f94d72aa7fae"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+--------------------+----+\n",
            "|        primaryTitle|titleType|              genres|year|\n",
            "+--------------------+---------+--------------------+----+\n",
            "|Istoriya grazhdan...|    movie|         Documentary|2021|\n",
            "|            Aufsätze|    short|               Short|2021|\n",
            "|Number 14: Late S...|    short|               Short|2023|\n",
            "|   Socialist Realism|    movie|               Drama|2023|\n",
            "|       Anything Goes|tvEpisode|  Comedy,Drama,Music|2022|\n",
            "|Histórias de Comb...|    movie|         Documentary|2022|\n",
            "|      Loading Ludwig|    movie|                  \\N|2022|\n",
            "|Beach Birds for C...|    short|               Short|2024|\n",
            "|  Neues in Wittstock|    movie|         Documentary|2021|\n",
            "|       Fado Lusitano|    short|Animation,History...|2023|\n",
            "|The Surgeon of th...|    movie|     Biography,Drama|2022|\n",
            "|        Bratrovrazda|    short|               Short|2024|\n",
            "|           Nine Ball|    movie|                  \\N|2023|\n",
            "|       Truth or Dare|    short|  Comedy,Drama,Short|2023|\n",
            "|             Kabaret|    short|     Animation,Short|2023|\n",
            "|         Konstrukcja|    short|     Animation,Short|2023|\n",
            "|         Przemijanie|    short|   Documentary,Short|2023|\n",
            "|We Will Meet in 1...|    short|               Short|2023|\n",
            "|E una domenica se...|  tvMovie|         Documentary|2022|\n",
            "|        Dur brzuszny|    short|   Documentary,Short|2023|\n",
            "+--------------------+---------+--------------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar quantos gêmeros/grupo de gêneros mais apareceram nos filmes\n",
        "from pyspark.sql.functions import count,col,asc,desc\n",
        "df_sum = df_year.groupBy('genres').count()\n",
        "df_sum.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXa5Ozn79pNU",
        "outputId": "8f19f4aa-7e76-407f-9bcb-aadd21aee28e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------+-----+\n",
            "|genres                     |count|\n",
            "+---------------------------+-----+\n",
            "|Comedy,Sport               |3697 |\n",
            "|Action,War,Western         |1    |\n",
            "|Action,Adventure,Fantasy   |7436 |\n",
            "|Documentary,Drama,Fantasy  |168  |\n",
            "|Adult,Comedy,Musical       |11   |\n",
            "|Crime,Horror,Short         |405  |\n",
            "|Adult,Horror,Sci-Fi        |40   |\n",
            "|Documentary,News,Reality-TV|608  |\n",
            "|Fantasy,Horror,Musical     |16   |\n",
            "|Action,Adult,Short         |5    |\n",
            "|Adult,Game-Show            |3    |\n",
            "|Animation,Sci-Fi,War       |62   |\n",
            "|Music,Musical,Short        |162  |\n",
            "|Adult,Comedy,Talk-Show     |3    |\n",
            "|Animation,Sport,Thriller   |53   |\n",
            "|Documentary,Western        |365  |\n",
            "|Adventure,Family,Fantasy   |5317 |\n",
            "|Comedy,Drama,Western       |245  |\n",
            "|Game-Show,Reality-TV       |52122|\n",
            "|Game-Show,Music,Mystery    |277  |\n",
            "+---------------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazer o mesmo cálculo, mas ordenando de forma descendente\n",
        "df_sum.orderBy(col('count').desc()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fbnd0fYw-C29",
        "outputId": "84c3c57e-ff34-4601-bea6-e89e755aa368"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-------+\n",
            "|           genres|  count|\n",
            "+-----------------+-------+\n",
            "|            Drama|1254900|\n",
            "|           Comedy| 734612|\n",
            "|        Talk-Show| 685713|\n",
            "|             News| 576649|\n",
            "|      Documentary| 532383|\n",
            "|    Drama,Romance| 515088|\n",
            "|               \\N| 495816|\n",
            "|       Reality-TV| 353243|\n",
            "|            Adult| 311806|\n",
            "|   News,Talk-Show| 248358|\n",
            "|            Short| 216810|\n",
            "|      Drama,Short| 208419|\n",
            "|           Family| 189750|\n",
            "|        Game-Show| 185528|\n",
            "|     Comedy,Short| 159514|\n",
            "|Documentary,Short| 154666|\n",
            "|            Sport| 132552|\n",
            "|          Romance| 116001|\n",
            "| Comedy,Talk-Show| 113480|\n",
            "|            Music| 108621|\n",
            "+-----------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste do 'Is In'\n",
        "df_year.select('primaryTitle','year','genres').filter(df_year.genres.isin('Comedy')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gySMTB6U-dsc",
        "outputId": "bd78c900-55a0-4c0d-addb-36eb17b84d80"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----+------+\n",
            "|        primaryTitle|year|genres|\n",
            "+--------------------+----+------+\n",
            "|          Salome Mad|1909|Comedy|\n",
            "|Jarní sen starého...|1913|Comedy|\n",
            "|     El bello Arturo|1913|Comedy|\n",
            "|   Le dernier pardon|1913|Comedy|\n",
            "|Fulano de Tal se ...|1916|Comedy|\n",
            "|My Husband's Gett...|1913|Comedy|\n",
            "|Pommy Arrives in ...|1913|Comedy|\n",
            "|Battle of Gettysgoat|1914|Comedy|\n",
            "|   Det blaa vidunder|1915|Comedy|\n",
            "| Brewster's Millions|1914|Comedy|\n",
            "|              C.O.D.|1914|Comedy|\n",
            "|   The Country Mouse|1914|Comedy|\n",
            "|The Education of ...|1914|Comedy|\n",
            "|            Engelein|1914|Comedy|\n",
            "|The Fates and Flo...|1914|Comedy|\n",
            "|The Perfect Thirt...|1914|Comedy|\n",
            "|A Florida Enchant...|1914|Comedy|\n",
            "|  The Fortune Hunter|1914|Comedy|\n",
            "|      Hombre o mujer|1914|Comedy|\n",
            "|I kammerherrens k...|1914|Comedy|\n",
            "+--------------------+----+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste do 'Not In'\n",
        "# basta colocar um '~' logo no começo dos argumentos do 'filter'\n",
        "# Teste do 'Is In'\n",
        "df_year.select('primaryTitle','year','genres').filter(~df_year.genres.isin('Comedy')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00iKi8zq_Gx0",
        "outputId": "ee99f1ce-b2c0-47e3-b37b-d879253905c2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----+--------------------+\n",
            "|        primaryTitle|year|              genres|\n",
            "+--------------------+----+--------------------+\n",
            "|          Carmencita|1894|   Documentary,Short|\n",
            "|Le clown et ses c...|1892|     Animation,Short|\n",
            "|      Pauvre Pierrot|1892|Animation,Comedy,...|\n",
            "|         Un bon bock|1892|     Animation,Short|\n",
            "|    Blacksmith Scene|1893|        Comedy,Short|\n",
            "|   Chinese Opium Den|1894|               Short|\n",
            "|Corbett and Court...|1894|         Short,Sport|\n",
            "|Edison Kinetoscop...|1894|   Documentary,Short|\n",
            "|          Miss Jerry|1894|             Romance|\n",
            "| Leaving the Factory|1895|   Documentary,Short|\n",
            "|Akrobatisches Pot...|1895|   Documentary,Short|\n",
            "|The Arrival of a ...|1896|   Documentary,Short|\n",
            "|The Photographica...|1895|   Documentary,Short|\n",
            "| The Waterer Watered|1895|        Comedy,Short|\n",
            "| Autour d'une cabine|1894|     Animation,Short|\n",
            "|Boat Leaving the ...|1895|   Documentary,Short|\n",
            "|Italienischer Bau...|1895|   Documentary,Short|\n",
            "|Das boxende Känguruh|1895|               Short|\n",
            "|    The Clown Barber|1898|        Comedy,Short|\n",
            "|      The Derby 1895|1895|Documentary,Short...|\n",
            "+--------------------+----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Usando SQL dentro do PySpark\n",
        "# Lembre da importância de usar VIEWS (Datacamp)\n",
        "df_year.createOrReplaceTempView('movies')\n",
        "spark.sql('SELECT year, COUNT(*) AS qtd FROM movies GROUP BY year ORDER BY qtd desc').show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezryfLvK_bVR",
        "outputId": "2f3977aa-bdd7-4e1e-c716-897b302de9a1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------+\n",
            "|year|qtd    |\n",
            "+----+-------+\n",
            "|null|1415326|\n",
            "|2021|495764 |\n",
            "|2022|474870 |\n",
            "|2018|451505 |\n",
            "|2019|446693 |\n",
            "|2017|445271 |\n",
            "|2023|432573 |\n",
            "|2020|427347 |\n",
            "|2016|421320 |\n",
            "|2015|396920 |\n",
            "|2014|376866 |\n",
            "|2013|355610 |\n",
            "|2012|331513 |\n",
            "|2011|292588 |\n",
            "|2010|260439 |\n",
            "|2024|247413 |\n",
            "|2009|227869 |\n",
            "|2008|216505 |\n",
            "|2007|200764 |\n",
            "|2006|179814 |\n",
            "+----+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fazendo JOINS e usando as duas tabelas"
      ],
      "metadata": {
        "id": "INr3rYGhCxDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# join\n",
        "# Aqui precisa ajustar conforme nosso dataset atualizado\n",
        "df.join(df_reviews, df.tconst == df_reviews.tconst, 'inner')\\\n",
        "    .select(df.primaryTitle, df.startYear, df.genres, df.titleType, df_reviews.averageRating, df_reviews.numVotes)\\\n",
        "    .show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOHH42kKDeM_",
        "outputId": "173241f3-4a58-40ec-e71c-85f2327fc2d3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------+---------+-------------------+---------+-------------+--------+\n",
            "|primaryTitle                          |startYear|genres             |titleType|averageRating|numVotes|\n",
            "+--------------------------------------+---------+-------------------+---------+-------------+--------+\n",
            "|Le clown et ses chiens                |1892     |Animation,Short    |short    |5.6          |283     |\n",
            "|Edison Kinetoscopic Record of a Sneeze|1894     |Documentary,Short  |short    |5.4          |2233    |\n",
            "|Autour d'une cabine                   |1894     |Animation,Short    |short    |6.1          |1216    |\n",
            "|Italienischer Bauerntanz              |1895     |Documentary,Short  |short    |4.6          |355     |\n",
            "|The Clown Barber                      |1898     |Comedy,Short       |short    |5.1          |32      |\n",
            "|The Bohemian Encampment               |1896     |Documentary,Short  |short    |3.6          |36      |\n",
            "|Cortège de tzar au Bois de Boulogne   |1896     |Documentary,Short  |short    |4.2          |34      |\n",
            "|Dessinateur: Reine Victoria           |1896     |Short              |short    |3.2          |30      |\n",
            "|The Mysterious Paper                  |1896     |Short              |short    |4.8          |35      |\n",
            "|Place du théâtre français             |1896     |Documentary,Short  |short    |4.5          |29      |\n",
            "|Rip Leaving Sleepy Hollow             |1896     |Drama,Short        |short    |4.4          |572     |\n",
            "|Buffalo Bill and Escort               |1897     |News,Short         |short    |5.1          |32      |\n",
            "|En classe                             |1897     |Comedy,Short       |short    |3.5          |14      |\n",
            "|Le cocher de fiacre endormi           |1897     |Comedy,Short       |short    |5.0          |27      |\n",
            "|Slagsmål i gamla Stockholm            |1897     |Short              |short    |3.9          |57      |\n",
            "|The X-Ray Fiend                       |1897     |Comedy,Horror,Short|short    |6.1          |1089    |\n",
            "|Výstavní párkar a lepic plakátù       |1898     |Comedy,Short       |short    |4.5          |141     |\n",
            "|A Sea Cave Near Lisbon                |1896     |Documentary,Short  |short    |4.9          |242     |\n",
            "|Le cuirassé Maine                     |1898     |Short,War          |short    |4.7          |24      |\n",
            "|The Deserter                          |1898     |Drama,Short        |short    |3.6          |12      |\n",
            "+--------------------------------------+---------+-------------------+---------+-------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_complete = df.join(df_reviews, df.tconst == df_reviews.tconst, 'inner')\\\n",
        "    .select(df.primaryTitle, df.startYear, df.genres, df.titleType, df_reviews.averageRating, df_reviews.numVotes)"
      ],
      "metadata": {
        "id": "g-YRRdwng15b"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Máximo sem salvar em variável\n",
        "# Qual o filme com mais votos\n",
        "from pyspark.sql.functions import max\n",
        "df_complete.agg(max('numVotes').alias('max_votes')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmRpgxQK8vpB",
        "outputId": "f9ba2543-29fc-47eb-dfce-bbce40767a1d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|max_votes|\n",
            "+---------+\n",
            "|  2942823|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Usando o resultado acima, podemos filtrar o filme com mais votos:\n",
        "df_max_votos = df_complete.filter(df_complete.numVotes == 2942823)\n",
        "df_max_votos.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHCSMT_k9OpE",
        "outputId": "3795a5c6-b4a2-4a63-bc13-1641211b72a7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+------+---------+-------------+--------+\n",
            "|        primaryTitle|startYear|genres|titleType|averageRating|numVotes|\n",
            "+--------------------+---------+------+---------+-------------+--------+\n",
            "|The Shawshank Red...|     1994| Drama|    movie|          9.3| 2942823|\n",
            "+--------------------+---------+------+---------+-------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao final inserir alguns testes de processamento com o\n",
        "```\n",
        "%%timeit\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "QD09KN3rElun"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J3Z2A2CKh2l6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}